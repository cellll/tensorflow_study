
# Training

- model.fit(x,y, batch_size, epochs)

1. x : input
2. y : label(실제 값) 
3. batch_size : batch=3 이면 3개 샘플(x) 랑 계산한 값 3개(y') 갖고 실제 값(y)랑 비교해서 weight 갱신(backpropagation)
4. epoch : 몇번 할건지 x가 100이고 epoch 2면  100 한번 다 돌리고 100 한번 더
   -> epoch이 마냥 높으면 overfitting 이 발생한다 : 똑같은 x 100개 갖고 100000000000번 돌리니까 100개 x하고만 잘맞음
   
   
   
- Hyperparameter : 학습을 돌리다가 학습 방법을 변경하거나 그만둬야 할때를 결정하는 파라미터 

1. 학습 방법 변경 :  하이퍼파라미터 갖고 최적의 학습방법 결정하는 것 하이퍼파라미터 튜닝  -> validation 을 쓴다
2. 학습 중단 : validation 그 정확도가 줄어드는 시점 -> overfitting 발생 시점


- Validation

1. 학습 방법 변경이나 중단 시점을 알기 위해서 validation set을 쓴다
  -> training set : t1, t2, t3 
  -> validation set : v1
  -> test : test1
  
  -> t1 t2 t3 으로 트레이닝하고 v1 으로 validation 하고 문제없으면 다시 t1 t2 t3 v1 // t1 t2 t3 v1 하고 마지막에 test1 으로 테스트
  
  
2. Cross-Validation : t1 t2 t3 v1 으로 고정해 놓으면 검증이 정확한게 아님

  -> t1 t2 t3 / v1 으로 검증
  -> t1 t2 v1 / t3 으로 검증
  -> t1 t3 v1 / t2 로 검증..
  
  이렇게 validaiton set 을 하나씩 번갈아가면서 하는것이 cross-validation. 계산한 모든 값의 평균값
  -> 계산량이 많아짐
  
  

  
  

   
